# Type Checking
Hmm, I seem to not be doing a good job of justifying my view on this.  We certainly went in that direction originally - shapes, colors, etc. for types.  Then we ran aground on unexpected gotchas and backed off.  We began doing evil things, like trying to force the editor to pre-check connections. That ended in pain and self-imposed complexity.  Analogy: humans use shaped connectors for electrical things today, but originally it was just "connect this wire to the wire, and be careful that you don't do something stupid".  The connector shapes we use today grew out of time and decades of experience instead of premature optimization.  Types, in software, don't come close to defining the "design rules" for each specific project.  Analogy: in electronics, voltage and current are NOT the total final determinants of whether something works.  For example, in laying out the design of a printed circuit, you have to apply "design rules" like wire length and proximity in addition to worrying about voltage and current.  If you lay out too many wires too close to each other for long runs, you get cross-talk and the circuit fails, even though it looks good on paper.  I wire-wrapped 24K of dynamic memory - beautifully arranged.  It didn't work.  I had to add "entropy" to the wiring, de-beautifying the wiring, rats-nest-ifying it. Finally I got 22K (not the full 24K) to work.  In software, there might be many "design rules" that apply on a per-project basis.  Generalization usually doesn't capture the subtleties required to make a project work.  Stepping back, we see that "type checking" is just code that examines other code.  "Static type checking" is an optimization (!!!) that moves *some* of the code-checking-code to one end of an arbitrary spectrum and can be executed all at once at a certain time.  Does that certain time *always* pertain to the problem-at-hand? A: no. Twisting a solution to fit into that arbitrary spectrum can lead to evil, self-imposed accidental complexity.  (Aside: we see exactly that today.  This twisting of the design space is the cause of bloatware.  For example, concurrency used to be simple, and needed about 10 bytes of code, whereas today, concurrency is feared and band-aided into behemoth Mbyte structures that inflict bad design decisions on projects (like needing to include all of Linux in a switch that controls a light bulb)).

So, I guess I'm saying, when you begin new project, make everything dynamic and eschew "static type checking".  Use "dynamic type checking" at first.  Once it works, hire a junior programmer to figure out how to make it run faster.  If you want to stop other junior programmers from screwing up the design, then add bits of code as training wheels that pre-check their modifications.  Maybe use colors and shapes to signal to the junior programmers where they need to be careful and thoughtless.

You are working on an existing code base.  Maybe you have already learned the "design rules" for this project.  So, maybe all of the above doesn't really apply to what you're doing.  OTOH, it helps to separate "what" you know the issues are from the "how" you intend to solve them.  I find that just writing the "what" down is helpful and guides the way that I write code. The "code" becomes surprisingly simple to write, even in a GPL not using an automatic compiler from higher-level concepts down to realization[^asm]. You are welcome to explain to me, again, what you think you want to accomplish.  I'd bet that just drawing the diagrams you sent me on Discord has helped you sort out what is important and not.  I've wasted huge amounts of time trying to make diagram compilers when the Real Big Bang comes from just drawing the diagrams and, hand-compiling them.  Using a compiler is just a nice-to-have and saves me only a small amount of time, relatively speaking (OTOH, this idea of no-compiler violates the principles of FDD.  Hmm.)

[^asm]: Maybe even in un-type-checked Assembler?  Good programmers "see" the design in their heads and write beautiful code without feeling the need to draw diagrams.  Other programmers tend "not to get it" and don't "see" the beauty of a "good programmer's" design.  They just see code.  How can "good programmers" sketch out their designs to make them more understandable to other programmers?  Some programmers wrote *structured programs* using raw assembler before "GOTO Considered Harmful" was published.  We want them to capture that essence and relate it to us in ways that we can understand.

My opinion: create boxes - Components - that check for the "design rules" of this project.  Little design-rule-checking pipelines (better than type-checking, assertion-checking, etc.  More flexible.  You can check for anything that seems important, not just what some pimply-faced PhD decided was important). When you get bored of creating the same boiler-plate design rules over and over again[^mmm], it's a signal that you are allowed to codify the checks into some kind of "static checks" (which may, or may not, be type checks).  This almost sounds like TDD, except that the programming language for TDD is stunted by premature optimization.  Maybe this is what we should be using AI code generation for?  First, use AI to create a boundary of relations that describe "what" the project is, then fill in the details inside the boundary with more detailed code (maybe with more AI)

[^mmm]: Note the similarity to what Brooks said in the Mythical Man Month.  Fail.  Fail again.  Succeed.  You want to find a way to fail-fast the first two times.  Using type-checked, bloatware languages ain't the way to fail-fast.

Answer this to yourself (and/or to me if you wish): "What" do you desire to gain by using these techniques?  I think that I hear you wanting to flexible-ize the Architecture so that you can tweak it and improve it.  That sounds like FDD in the 2nd pass of failure.  Or maybe, you are trying to graduate from stage 2 failure to stage 3 success?  Today, most software is released during phase 1 failure and we gain phase 2 experience by "listening to our users" and providing them with frequent updates (holy shades of Agile!).  Maybe thinking of it as 3 stages is "too quantized", maybe it's a continuum?  Real Engineers chop the work up into big lumps: (1) Architecture (2) Engineering (3) Implementation (4) Q/A.  Then, rinse and repeat - lump (4) feeds back to lump (1).  Going from lump (1) to lump (4) in one fell swoop has a name - "Waterfall method".  We must iterate designs.  We must fail fast when we can.  And, learn from our mistakes.  Our programming languages should not impede this process.  I think that decoupling of software units encourages fail-fast-ness.